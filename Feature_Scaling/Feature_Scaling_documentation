# Project: Restaurant Location Recommendation Tool & Analysis ##

# Goal
The goal of this step is to preprocess the restaurant dataset so it is ready for machine learning. This includes:
   1. Converting categorical (text) columns into numerical values using Label Encoding,
   2. Defining features (X) and target (y),
   3. Applying Normalization (Min-Max Scaling) and Standardization (Z-score Scaling) to bring all features to a comparable scale, and
   4. Preparing the scaled data for use in machine learning models.

# Objective
To prepare the dataset for machine learning models by:
 1. Converting categorical variables into numerical format using Label Encoding.
 2. Scaling the numerical features using two popular methods:
      Min-Max Normalization
      Standardization (Z-score Scaling)
 3. Feature scaling is the process of making sure all the numerical values in your dataset are on a similar scale.

Feature scaling ensures that all input features contribute equally to the model’s learning process and prevents features with larger numerical ranges from dominating others.

# Why Feature Scaling?
Many machine learning algorithms (e.g., logistic regression, KNN, SVM, gradient descent-based models) are sensitive to the scale of input features. If features vary widely in magnitude, models may converge slowly or yield inaccurate results.

# Feature Scaling Steps

1. Import Required Libraries

<pre>from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split </pre>

MinMaxScaler: Used for normalization (scales values to [0, 1]).

StandardScaler: Used for standardization (makes mean = 0, std = 1).

train_test_split: (not used here but often used to split data into training and test sets).

2. Encode Categorical Columns

<pre>cat_cols = ['Restaurant location', 'Demographics', 'Local Amenities', 'Cuisine Type',
            'Opening Hours', 'Nearby Attractions', 'Signature Dish Name', 'Footfall_Peak'] 
for col in cat_cols:
    df[col] = le.fit_transform(df[col].astype(str))
    print(f"Column '{col}' encoded successfully.")</pre>

Why? Machine learning models cannot work directly with text data.

Converts each categorical column into numerical labels (e.g., "Downtown" → 0, "Suburban" → 1).

Ensures all values are strings before encoding, avoiding errors.

3. Define Features and Target

<pre>X = df[['Restaurant location', 'Demographics', 'Footfall', 'Competition',
        'Local Amenities', 'Cuisine Type', 'Average Meal Price',
        'Parking Availability', 'Opening Hours', 'Nearby Attractions',
        'Distance from City Centre', 'Signature Dish Name', 'Seating Capacity',
        'Distance_to_Metro', 'Average_Income', 'Nearby_Competitors',
        'Footfall_Peak', 'Near_Tourist_Spot', 'Parking_Available']]

y = df['Rating']</pre>

Features (X): Input data used to train the model (restaurant details).

Target (y): The output we want to predict (here, the Rating).

4. Normalization (Min-Max Scaling)

<pre>from sklearn.preprocessing import MinMaxScaler</pre>
<pre>scaler_norm = MinMaxScaler() </pre>

Creates a Min-Max scaler object.

<pre>X_normalized = scaler_norm.fit_transform(X_encoded) 
print(" Normalization (Min-Max Scaling) done!") </pre>

Scales all feature values to be between 0 and 1.

Confirms that normalization is complete.

5. Standardization (Z-score Scaling)

<pre>from sklearn.preprocessing import StandardScaler</pre>
<pre>scaler_std = StandardScaler() </pre>

Creates a StandardScaler object.

<pre>X_standardized = scaler_std.fit_transform(X_encoded) </pre>

Scales features so that:

   1. Mean = 0
   2. Standard deviation = 1

<pre>print(" Standardization (Z-score Scaling) done!")
print(" Standardized Feature Sample:\n", X_standardized[:5])</pre>

Confirms that standardization is complete.

6. Convert to DataFrames for Better Viewing

<pre>print("\n Data preprocessing completed. You can now train models using:")
print("   ▶ X_normalized for normalized training")
print("   ▶ X_standardized for standardized training")</pre>

Confirms that preprocessing is complete.

Provides a choice: models can be trained with normalized or standardized features depending on which works better.

# Summary
 
In this process, we prepared our restaurant dataset for machine learning by first separating the input features (X) and target variable (y). Categorical features such as "Footfall_Peak" and "Parking_Available" were converted into numerical form using Label Encoding to make them suitable for model input. Then, two popular feature scaling techniques were applied:

Min-Max Normalization, which scales all feature values to a fixed range between 0 and 1, and

Standardization (Z-score Scaling), which transforms features to have a mean of 0 and a standard deviation of 1.

The result was two clean, numerical datasets (X_normalized and X_standardized) that are now ready for training machine learning models. These transformations ensure that features contribute equally to model learning and improve algorithm convergence and performance.










